# -*- coding: utf-8 -*-
"""wav2vec_all_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b0z9wZdFexQfK48HxcSt1ftc57kAp3Sr
"""

from transformers import AutoProcessor, Wav2Vec2Model
import torch
import torch.nn as nn


def process_wav(wav_file, model_name="facebook/wav2vec2-base-960h"):
    # Load processor and model
    processor = AutoProcessor.from_pretrained(model_name)
    model = Wav2Vec2Model.from_pretrained(model_name)

    # Initialize an empty list to store last_hidden_states
    inputs = processor(wav_file, sampling_rate=16000, return_tensors='pt')

    with torch.no_grad():
        outputs = model(**inputs)

    last_hidden_states = outputs.last_hidden_state

    # 使用切片进行降采样
    downsampled_last_hidden_states = last_hidden_states[:, ::2, :]

    return downsampled_last_hidden_states


def normalize_hidden_states(hidden_states):

    min_values, _ = torch.min(hidden_states, dim=1, keepdim=True)
    max_values, _ = torch.max(hidden_states, dim=1, keepdim=True)

    # Normalize the hidden states
    normalized_states = (hidden_states - min_values) / (max_values - min_values)   

    return normalized_states


# 定义深层神经网络模型
class DeepRegressionModel(nn.Module):
    def __init__(self, input_size, hidden_sizes, output_size):
        super(DeepRegressionModel, self).__init__()
        layers = []
        for i in range(len(hidden_sizes)):
            if i == 0:
                layers.append(nn.Linear(input_size, hidden_sizes[i]))
            else:
                layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))
            layers.append(nn.ReLU())
        layers.append(nn.Linear(hidden_sizes[-1], output_size))
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        return self.model(x)



